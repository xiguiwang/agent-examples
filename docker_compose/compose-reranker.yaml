services:
  Qwen3-Reranker-4B:
    container_name: Qwen3-Reranker-4B
    restart: always
    image: vllm-openai:vllm-cpu 
    ipc: host
    environment:
      VLLM_DEVICE: "cpu"
      VLLM_USE_CPU_OPS: "1"
      VLLM_LOGGING_LEVEL: "DEBUG"
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      HF_TOKEN: ${HF_TOKEN}
      HF_HUB_OFFLINE: "1"
    deploy:
      resources:
        reservations:
          devices: []
    volumes:
      - "${HF_HOME}:/root/.cache/huggingface"
    #command: ['--model', 'Qwen/Qwen3-Reranker-4B',  '--served-model-name', 'Qwen3-Reranker-4B',  '--gpu-memory-utilization', '0.90', '--hf_overrides','{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}']
    command: [
        '--model', 'Qwen/Qwen3-Reranker-4B',  
        '--served-model-name', 'Qwen3-Reranker-4B',  
        '--max-model-len', '16384',
        '--hf_overrides','{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
    ]
    ports:
      - 8012:8000
